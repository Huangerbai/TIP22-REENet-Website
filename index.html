<!DOCTYPE HTML>
<html class="no-js">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <title>REENet</title>
    <meta name="description" content="Lithium Description" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <link href="css/plugins.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/application.css" media="screen" rel="stylesheet" type="text/css" />
  </head>

<body>

    <!-- ABOUT -->

    <section id="page-about" class="section">
      <div align="center" style="padding-bottom: 100px;">
        <p class="copy-02">TIP 2022</p>
        <p class="heading h-01">Towards Low Light Enhancement with RAW Images</p>

        <p class="copy-02">
          <a href="https://Huangerbai.github.io/">Haofeng Huang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://flyywh.github.io/">Wenhan Yang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://huzi96.github.io/">Yueyu Hu</a> &nbsp;&nbsp;&nbsp;
          <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
          <a href="https://eecs.pku.edu.cn/info/1459/9475.htm">Ling-Yu Duan</a> &nbsp;&nbsp;&nbsp;
        </p>
      </div>

      <div class="site-inner">
        <h3 class="heading h-03">Abstract</h3>
        <div class="columns">
          <aside>
            <p class="copy-02">Face detection in low light scenarios is challenging but vital to many practical applications, e.g., surveillance video, autonomous driving at night. Most existing face detectors heavily rely on extensive annotations, while collecting data is time-consuming and laborious. To reduce the burden of building new datasets for low light conditions, we make full use of existing normal light data and explore how to adapt face detectors from normal light to low light. The challenge of this task is that the gap between normal and low light is too huge and complex for both pixel-level and object-level. Therefore, most existing low-light enhancement and adaptation methods do not achieve desirable performance. To address the issue, we propose a joint High-Low Adaptation (HLA) framework. Through a bidirectional low-level adaptation and multi-task high-level adaptation scheme, our HLA-Face outperforms state-of-the-art methods even without using dark face labels for training.</p>
          </aside>
          <aside>
            <div align="center" style="padding-bottom:10px">
              <img src="teasor.jpg" width=100%> <br>
            </div>
            <p class='copy-02' style="color:#888888">Dark face detection visual results and our learning paradigm. Compared with the result of DSFD [1] on original low light images and the enhanced version by LIME [2], our method can better recognize the faces in dark scenarios.
            </p>
          </aside>
        </div>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Method</h3>
        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="motivation.jpg" width=90%> <br>
        </div>

        <p class='copy-02'>Motivation: comparison of different adaptive low light detection techniques. L: low light data. H: normal light data. Existing enhancement-based, darkening-based, and feature adaptation methods either ignore the high-level gap, or have limited effects due to the huge and complex gap between L and H. Our method instead considers both low-level and high-level adaptation, therefore achieves better performance.
        </p>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="framework_2.jpg" width=70%> <br>
        </div>

        <p class='copy-02'>Framework: <a style="color:#4C6E8B"><b>LOW-LEVEL</b></a> adaptation fills the gap by creating intermediate states. We bidirectionally brighten the low light data as well as distort the normal light data with noise and color bias. Based on the built intermediate states, we use multi-task cross-domain self-supervised learning to fill the <a style="color:#85937E"><b>HIGH-LEVEL</b></a> gap.
        </p>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Selected Experimental Results</h3>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="comp_map.jpg" width=60%> <br>
        </div>

        <div align="center">
          <p class='copy-02'>Precision-Recall (PR) curves on DARK FACE.
          </p>
        </div>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="enh_comp.jpg" width=90%> <br>
        </div>



        <p class='copy-02'>Qualitative comparison of different enhancement-based methods. (a) Input low light image and the ground truth boxes. (b)-(g) Results of low-light enhancement methods with DSFD [1]. (h) Our result.
        </p>

      </div>



      <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <ul style="line-height:1.5; padding-left: 50px; padding-right: 50px">
          　　<li class="copy-02"> Paper: <a href="https://arxiv.org/abs/2112.14022">arXiv</a></li>
          　　<li class="copy-02"> Code: Coming soon</li>
          </ul>
      </div>
      

      <div class="site-inner" style="padding-top:50px;">
        <p class='heading h-03'> Citation</p>
        <p class="copy-02"> @ARTICLE{Huang_TIP_2022, <br>
        &nbsp; &nbsp; author = {Huang, Haofeng and Yang, Wenhan and Hu, Yueyu and Liu, Jiaying and Duan, Ling-Yu}, <br>
        &nbsp; &nbsp; title = {Towards Low Light Enhancement With RAW Images}, <br>
        &nbsp; &nbsp; journal={IEEE Transactions on Image Processing}, <br>
        &nbsp; &nbsp; volume={31}, <br>
        &nbsp; &nbsp; pages={1391-1405}, <br>
        &nbsp; &nbsp; year={2022}, <br>
        } <br> 
        </p>
      </div>


    <section id="page-about" class="section">

</body>
</html>
