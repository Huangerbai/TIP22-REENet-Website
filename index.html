<!DOCTYPE HTML>
<html class="no-js">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
    <title>REENet</title>
    <meta name="description" content="Lithium Description" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <link href="css/plugins.css" media="screen" rel="stylesheet" type="text/css" />
    <link href="css/application.css" media="screen" rel="stylesheet" type="text/css" />
  </head>

<body>

    <!-- ABOUT -->

    <section id="page-about" class="section">
      <div align="center" style="padding-bottom: 100px;">
        <p class="copy-02">TIP 2022</p>
        <p class="heading h-01">Towards Low Light Enhancement with RAW Images</p>

        <p class="copy-02">
          <a href="https://Huangerbai.github.io/">Haofeng Huang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://flyywh.github.io/">Wenhan Yang</a> &nbsp;&nbsp;&nbsp;
          <a href="https://huzi96.github.io/">Yueyu Hu</a> &nbsp;&nbsp;&nbsp;
          <a href="https://www.icst.pku.edu.cn/struct/people/liujiaying.html">Jiaying Liu</a>
          <a href="https://eecs.pku.edu.cn/info/1459/9475.htm">Ling-Yu Duan</a> &nbsp;&nbsp;&nbsp;
        </p>
      </div>

      <div class="site-inner">
        <h3 class="heading h-03">Abstract</h3>
        <div class="columns">
          <aside>
            <p class="copy-02">In this paper, we make the first benchmark effort to elaborate on the superiority of using RAW images in the low light enhancement and develop a novel alternative route to utilize RAW images in a more flexible and practical way. Inspired by a full consideration on the typical image processing pipeline, we are inspired to develop a new evaluation framework, Factorized Enhancement Model (FEM), which decomposes the properties of RAW images into measurable factors and provides a tool for exploring how properties of RAW images affect the enhancement performance empirically. The empirical benchmark results show that the Linearity of data and Exposure Time recorded in meta-data play the most critical role, which brings distinct performance gains in various measures over the approaches taking the sRGB images as input. With the insights obtained from the benchmark results in mind, a RAW-guiding Exposure Enhancement Network (REENet) is developed, which makes trade-offs between the advantages and inaccessibility of RAW images in real applications in a way of using RAW images only in the training phase. REENet projects sRGB images into linear RAW domains to apply constraints with corresponding RAW images to reduce the difficulty of modeling training. After that, in the testing phase, our REENet does not rely on RAW images. Experimental results demonstrate not only the superiority of REENet to state-of-the-art sRGB-based methods and but also the effectiveness of the RAW guidance and all components.</p>
          </aside>
        </div>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Method</h3>
        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="motivation.jpg" width=90%> <br>
        </div>

        <p class='copy-02'>Motivation: comparison of different adaptive low light detection techniques. L: low light data. H: normal light data. Existing enhancement-based, darkening-based, and feature adaptation methods either ignore the high-level gap, or have limited effects due to the huge and complex gap between L and H. Our method instead considers both low-level and high-level adaptation, therefore achieves better performance.
        </p>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="framework_2.jpg" width=70%> <br>
        </div>

        <p class='copy-02'>Framework: <a style="color:#4C6E8B"><b>LOW-LEVEL</b></a> adaptation fills the gap by creating intermediate states. We bidirectionally brighten the low light data as well as distort the normal light data with noise and color bias. Based on the built intermediate states, we use multi-task cross-domain self-supervised learning to fill the <a style="color:#85937E"><b>HIGH-LEVEL</b></a> gap.
        </p>
      </div>

      <div class="site-inner" style="padding-top: 50px;">
        <h3 class="heading h-03">Selected Experimental Results</h3>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="comp_map.jpg" width=60%> <br>
        </div>

        <div align="center">
          <p class='copy-02'>Precision-Recall (PR) curves on DARK FACE.
          </p>
        </div>

        <br><br>

        <div align="center" style="padding-top:20px;padding-bottom:10px">
          <img src="enh_comp.jpg" width=90%> <br>
        </div>



        <p class='copy-02'>Qualitative comparison of different enhancement-based methods. (a) Input low light image and the ground truth boxes. (b)-(g) Results of low-light enhancement methods with DSFD [1]. (h) Our result.
        </p>

      </div>



      <div class="site-inner" style="padding-top:50px;">
        <p class="heading h-03"> Resources </p> 
          <ul style="line-height:1.5; padding-left: 50px; padding-right: 50px">
          　　<li class="copy-02"> Paper: <a href="https://arxiv.org/abs/2112.14022">arXiv</a></li>
          　　<li class="copy-02"> Code: Coming soon</li>
          </ul>
      </div>
      

      <div class="site-inner" style="padding-top:50px;">
        <p class='heading h-03'> Citation</p>
        <p class="copy-02"> @ARTICLE{Huang_TIP_2022, <br>
        &nbsp; &nbsp; author = {Huang, Haofeng and Yang, Wenhan and Hu, Yueyu and Liu, Jiaying and Duan, Ling-Yu}, <br>
        &nbsp; &nbsp; title = {Towards Low Light Enhancement With RAW Images}, <br>
        &nbsp; &nbsp; journal={IEEE Transactions on Image Processing}, <br>
        &nbsp; &nbsp; volume={31}, <br>
        &nbsp; &nbsp; pages={1391-1405}, <br>
        &nbsp; &nbsp; year={2022}, <br>
        } <br> 
        </p>
      </div>


    <section id="page-about" class="section">

</body>
</html>
